{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import unzip_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip_data(\"nlp-getting-started.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7613\n",
      "3263\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_random_sample():\n",
    "    n = np.random.randint(len(train_df)-1)\n",
    "    row = train_df.iloc[n:n+1,:].itertuples()\n",
    "    for x in row:\n",
    "        print('Target :',x.target)\n",
    "        print('Text :',x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target : 0\n",
      "Text : that exploded &amp; brought about the\n",
      "beginning of universe matches what's\n",
      "mentioned in the versethe heaven and Earth\n",
      "(thus the universe)\n"
     ]
    }
   ],
   "source": [
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df['text'].to_numpy()\n",
    "y = train_df['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, val_sentences, train_targets, val_targets = train_test_split(X,y,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 762)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences),len(val_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'McFadden Reportedly to Test Hamstring Thursday' via @TeamStream http://t.co/jWq4KvJH2j\",\n",
       "       'w--=-=-=-[ NEMA warns Nigerians to prepare for drought http://t.co/5uoOPhSqU3',\n",
       "       \"When I was cooking earlier I got electrocuted some crucial ?????? now I'm psychic lol\",\n",
       "       \"I'm On Fire.  http://t.co/WATsmxYTVa\",\n",
       "       \"More than 40 families affected by the fatal outbreak of Legionnaires' disease in Edinburgh are to sue two comp... http://t.co/vsoXioOy78\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_len = 10000\n",
    "max_len = round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "text_vectorizer = TextVectorization(max_tokens = max_vocab_len,\n",
    "                                    output_mode = 'int',\n",
    "                                    output_sequence_length = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 20:46:21.877240: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 476,  759, 2183,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer(['Typhoon Soudelor approaches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5: ['pakthey', 'pakistan\\x89Ûªs', 'pakistans', 'pajamas', 'paints']\n"
     ]
    }
   ],
   "source": [
    "top_5 = text_vectorizer.get_vocabulary()[:5]\n",
    "bottom_5 = text_vectorizer.get_vocabulary()[-5:]\n",
    "print(\"top 5:\",top_5)\n",
    "print(\"Bottom 5:\",bottom_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = Embedding(input_dim=max_vocab_len,\n",
    "                       output_dim = 128,\n",
    "                       embeddings_initializer = 'uniform',\n",
    "                       input_length = max_len,\n",
    "                       name = 'embedding_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 1.0960974e-02,  1.2876201e-02,  2.5147285e-02, ...,\n",
       "         -4.3889154e-02, -7.5126775e-03, -3.5486721e-02],\n",
       "        [-4.3975066e-02, -2.2009075e-02, -5.0729625e-03, ...,\n",
       "         -4.9662746e-02, -2.7155017e-02,  9.8718517e-03],\n",
       "        [-2.3431873e-02,  6.7074299e-03,  2.4393622e-02, ...,\n",
       "          4.8846696e-02,  2.2456050e-03,  4.2378727e-02],\n",
       "        ...,\n",
       "        [ 1.5087612e-03,  8.2932413e-05,  2.1836162e-03, ...,\n",
       "         -1.8462051e-02, -2.0860290e-02,  3.9239358e-02],\n",
       "        [ 1.5087612e-03,  8.2932413e-05,  2.1836162e-03, ...,\n",
       "         -1.8462051e-02, -2.0860290e-02,  3.9239358e-02],\n",
       "        [ 1.5087612e-03,  8.2932413e-05,  2.1836162e-03, ...,\n",
       "         -1.8462051e-02, -2.0860290e-02,  3.9239358e-02]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentence = random.choice(train_sentences)\n",
    "tok = text_vectorizer([random_sentence])\n",
    "embeddings(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7782152230971129"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences,val_targets)\n",
    "baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_targets = model_0.predict(val_sentences)\n",
    "pred_targets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaseLine Model (Naive Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = calculate_results(val_targets,pred_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-1 (Simple Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensorboard callback (need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(1,),dtype='string')\n",
    "x = text_vectorizer(inputs)\n",
    "x = embeddings(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "model_1 = tf.keras.Model(inputs,outputs,name='model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/simple_dense_model/20240125-204623\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 2s 6ms/step - loss: 0.6125 - accuracy: 0.6847 - val_loss: 0.5415 - val_accuracy: 0.7703\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.4405 - accuracy: 0.8180 - val_loss: 0.4842 - val_accuracy: 0.7927\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.3447 - accuracy: 0.8610 - val_loss: 0.4810 - val_accuracy: 0.7861\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.2829 - accuracy: 0.8913 - val_loss: 0.4856 - val_accuracy: 0.7874\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.2343 - accuracy: 0.9146 - val_loss: 0.5034 - val_accuracy: 0.7808\n",
      "Epoch 6/10\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.1988 - accuracy: 0.9283 - val_loss: 0.5285 - val_accuracy: 0.7756\n",
      "Epoch 7/10\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1697 - accuracy: 0.9403 - val_loss: 0.5562 - val_accuracy: 0.7717\n",
      "Epoch 8/10\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1464 - accuracy: 0.9512 - val_loss: 0.5932 - val_accuracy: 0.7703\n",
      "Epoch 9/10\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1279 - accuracy: 0.9561 - val_loss: 0.6268 - val_accuracy: 0.7507\n",
      "Epoch 10/10\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.1140 - accuracy: 0.9603 - val_loss: 0.6554 - val_accuracy: 0.7598\n"
     ]
    }
   ],
   "source": [
    "model_1_history = model_1.fit(train_sentences,\n",
    "            train_targets,\n",
    "            epochs=10,\n",
    "            validation_data=(val_sentences,val_targets),\n",
    "            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, experiment_name=\"simple_dense_model\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 796us/step - loss: 0.6554 - accuracy: 0.7598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6553800702095032, 0.7598425149917603]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(val_sentences,val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 728us/step\n"
     ]
    }
   ],
   "source": [
    "pred_targets = model_1.predict(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00766716],\n",
       "       [0.10855565],\n",
       "       [0.09960067],\n",
       "       [0.00154656],\n",
       "       [0.73293215]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_targets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds = tf.squeeze(tf.round(pred_targets))\n",
    "model_1_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_results = calculate_results(val_targets,model_1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 77.82, New accuracy: 75.98, Difference: -1.84\n",
      "Baseline precision: 0.79, New precision: 0.76, Difference: -0.03\n",
      "Baseline recall: 0.78, New recall: 0.76, Difference: -0.02\n",
      "Baseline f1: 0.77, New f1: 0.76, Difference: -0.01\n"
     ]
    }
   ],
   "source": [
    "# Create a helper function to compare our baseline results to new model results\n",
    "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
    "  for key, value in baseline_results.items():\n",
    "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
    "\n",
    "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
    "                                new_model_results=model_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_2_embedding = layers.Embedding(input_dim=max_vocab_len,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_len,\n",
    "                                     name=\"embedding_2\")\n",
    "\n",
    "\n",
    "# Create LSTM model\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_2_embedding(x)\n",
    "print(x.shape)\n",
    "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
    "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
    "print(x.shape)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/LSTM/20240125-204638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 15ms/step - loss: 0.5153 - accuracy: 0.7432 - val_loss: 0.4659 - val_accuracy: 0.7979\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.3159 - accuracy: 0.8718 - val_loss: 0.5317 - val_accuracy: 0.7861\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.2186 - accuracy: 0.9194 - val_loss: 0.5282 - val_accuracy: 0.7717\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.1484 - accuracy: 0.9444 - val_loss: 0.7042 - val_accuracy: 0.7559\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1076 - accuracy: 0.9600 - val_loss: 0.9149 - val_accuracy: 0.7572\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                              train_targets,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_targets),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"LSTM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.9149 - accuracy: 0.7572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9149055480957031, 0.7572178244590759]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(val_sentences,val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model_2_preds = model_2.predict(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0027464 ],\n",
       "       [0.23027453],\n",
       "       [0.00524693],\n",
       "       [0.0032164 ],\n",
       "       [0.996755  ],\n",
       "       [0.06060776],\n",
       "       [0.00124677],\n",
       "       [0.0211354 ],\n",
       "       [0.00998242],\n",
       "       [0.9986603 ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_preds = tf.squeeze(tf.round(model_2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_results = calculate_results(val_targets,model_2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.7217847769029,\n",
       " 'precision': 0.7568414957109175,\n",
       " 'recall': 0.7572178477690289,\n",
       " 'f1': 0.7551969389653065}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 77.82, New accuracy: 75.72, Difference: -2.10\n",
      "Baseline precision: 0.79, New precision: 0.76, Difference: -0.04\n",
      "Baseline recall: 0.78, New recall: 0.76, Difference: -0.02\n",
      "Baseline f1: 0.77, New f1: 0.76, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
    "                                new_model_results=model_2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_embeddings = Embedding(input_dim = max_vocab_len,\n",
    "                               output_dim = 128,\n",
    "                               embeddings_initializer = 'normal',\n",
    "                               input_length = max_len,\n",
    "                               name = 'embedings_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(1,),dtype='string')\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_3_embeddings(x)\n",
    "x = layers.GRU(64,return_sequences = True)(x)\n",
    "x = layers.GRU(64)(x)\n",
    "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model_3 = tf.keras.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(loss = 'binary_crossentropy',\n",
    "                optimizer = 'adam',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 19ms/step - loss: 0.5341 - accuracy: 0.7260 - val_loss: 0.4693 - val_accuracy: 0.7992\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.3255 - accuracy: 0.8672 - val_loss: 0.5206 - val_accuracy: 0.7664\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.2217 - accuracy: 0.9169 - val_loss: 0.5182 - val_accuracy: 0.7690\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1526 - accuracy: 0.9469 - val_loss: 0.6688 - val_accuracy: 0.7690\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1166 - accuracy: 0.9615 - val_loss: 0.7798 - val_accuracy: 0.7664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28c1ef0d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(train_sentences,\n",
    "            train_targets,\n",
    "            epochs = 5,\n",
    "            validation_data = (val_sentences,val_targets),\n",
    "            callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7798 - accuracy: 0.7664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7798168063163757, 0.7664042115211487]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(val_sentences,val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model_3_preds = model_3.predict(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_preds = tf.squeeze(tf.round(model_3_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.64041994750657,\n",
       " 'precision': 0.7699172766005876,\n",
       " 'recall': 0.7664041994750657,\n",
       " 'f1': 0.7620808707395365}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_results = calculate_results(val_targets,model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 77.82, New accuracy: 76.64, Difference: -1.18\n",
      "Baseline precision: 0.79, New precision: 0.77, Difference: -0.02\n",
      "Baseline recall: 0.78, New recall: 0.77, Difference: -0.01\n",
      "Baseline f1: 0.77, New f1: 0.76, Difference: -0.01\n"
     ]
    }
   ],
   "source": [
    "compare_baseline_to_new_results(baseline_results, model_3_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_embeddings = Embedding(input_dim = max_vocab_len,\n",
    "                               output_dim = 128,\n",
    "                               embeddings_initializer = 'normal',\n",
    "                               input_length = max_len,\n",
    "                               name = 'model_4_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape = (1,),dtype = 'string')\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_4_embeddings(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
    " \n",
    "model_4 = tf.keras.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(loss ='binary_crossentropy',\n",
    "                optimizer = 'adam',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 15ms/step - loss: 0.5168 - accuracy: 0.7463 - val_loss: 0.4674 - val_accuracy: 0.7979\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.3201 - accuracy: 0.8676 - val_loss: 0.4811 - val_accuracy: 0.7966\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.2184 - accuracy: 0.9168 - val_loss: 0.5467 - val_accuracy: 0.7953\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1438 - accuracy: 0.9489 - val_loss: 0.7593 - val_accuracy: 0.7664\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.0992 - accuracy: 0.9631 - val_loss: 0.8775 - val_accuracy: 0.7664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28c1c80d0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(train_sentences,\n",
    "            train_targets,\n",
    "            epochs = 5,\n",
    "            validation_data = (val_sentences,val_targets),\n",
    "            callbacks = [model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2e19e5b20>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model_4.load_weights(checkpoint_filepath)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x2e19f3c10>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46741294860839844, 0.7979002594947815]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.evaluate(val_sentences,val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model_4_preds = model_4.predict(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_preds = tf.squeeze(tf.round(model_4_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.79002624671917,\n",
       " 'precision': 0.8112297050595747,\n",
       " 'recall': 0.7979002624671916,\n",
       " 'f1': 0.7917197430245241}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate bidirectional RNN model results\n",
    "model_4_results = calculate_results(val_targets, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 77.82, New accuracy: 79.79, Difference: 1.97\n",
      "Baseline precision: 0.79, New precision: 0.81, Difference: 0.02\n",
      "Baseline recall: 0.78, New recall: 0.80, Difference: 0.02\n",
      "Baseline f1: 0.77, New f1: 0.79, Difference: 0.02\n"
     ]
    }
   ],
   "source": [
    "compare_baseline_to_new_results(baseline_results, model_4_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_5_embedding = layers.Embedding(input_dim=max_vocab_len,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_len,\n",
    "                                     name=\"embedding_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(1,),dtype = 'string')\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_5_embedding(x)\n",
    "x = layers.Conv1D(filters = 32, kernel_size = 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model_5 = tf.keras.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,300,545\n",
      "Trainable params: 1,300,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile Conv1D model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Get a summary of our 1D convolution model\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/Conv1D/20240125-212937\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.5672 - accuracy: 0.7087 - val_loss: 0.4801 - val_accuracy: 0.7953\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.3400 - accuracy: 0.8589 - val_loss: 0.4928 - val_accuracy: 0.7795\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.2094 - accuracy: 0.9237 - val_loss: 0.5901 - val_accuracy: 0.7703\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1331 - accuracy: 0.9548 - val_loss: 0.6833 - val_accuracy: 0.7533\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.0947 - accuracy: 0.9680 - val_loss: 0.7617 - val_accuracy: 0.7546\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_5_history = model_5.fit(train_sentences,\n",
    "                              train_targets,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_targets),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"Conv1D\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00317595],\n",
       "       [0.21305431],\n",
       "       [0.02735371],\n",
       "       [0.02046004],\n",
       "       [0.06298198],\n",
       "       [0.12972127],\n",
       "       [0.00397308],\n",
       "       [0.02439901],\n",
       "       [0.02003684],\n",
       "       [0.9982359 ]], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with model_5\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model_5 prediction probabilities to labels\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.45931758530183,\n",
       " 'precision': 0.7547288990872333,\n",
       " 'recall': 0.7545931758530183,\n",
       " 'f1': 0.7519424004405716}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_5 evaluation metrics \n",
    "model_5_results = calculate_results(y_true=val_targets, \n",
    "                                    y_pred=model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 77.82, New accuracy: 75.46, Difference: -2.36\n",
      "Baseline precision: 0.79, New precision: 0.75, Difference: -0.04\n",
      "Baseline recall: 0.78, New recall: 0.75, Difference: -0.02\n",
      "Baseline f1: 0.77, New f1: 0.75, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare model_5 results to baseline \n",
    "compare_baseline_to_new_results(baseline_results, model_5_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape = [],\n",
    "                                        dtype = tf.string,\n",
    "                                        trainable = False,\n",
    "                                        name ='USE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "],name = 'model_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20240125-220017\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 5ms/step - loss: 0.5102 - accuracy: 0.7758 - val_loss: 0.4285 - val_accuracy: 0.8005\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.4181 - accuracy: 0.8159 - val_loss: 0.4092 - val_accuracy: 0.8189\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.4039 - accuracy: 0.8212 - val_loss: 0.4025 - val_accuracy: 0.8202\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.3944 - accuracy: 0.8281 - val_loss: 0.4006 - val_accuracy: 0.8215\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.3874 - accuracy: 0.8283 - val_loss: 0.3981 - val_accuracy: 0.8136\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of pretrained embeddings\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_targets,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_targets),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0752045 ],\n",
       "       [0.08298109],\n",
       "       [0.449591  ],\n",
       "       [0.16008449],\n",
       "       [0.29896495],\n",
       "       [0.08966858],\n",
       "       [0.12097116],\n",
       "       [0.08799354],\n",
       "       [0.34233576],\n",
       "       [0.7796945 ]], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.36482939632546,\n",
       " 'precision': 0.8148546809795163,\n",
       " 'recall': 0.8136482939632546,\n",
       " 'f1': 0.811929377449037}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 6 performance metrics\n",
    "model_6_results = calculate_results(val_targets, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 77.82, New accuracy: 81.36, Difference: 3.54\n",
      "Baseline precision: 0.79, New precision: 0.81, Difference: 0.02\n",
      "Baseline recall: 0.78, New recall: 0.81, Difference: 0.04\n",
      "Baseline f1: 0.77, New f1: 0.81, Difference: 0.04\n"
     ]
    }
   ],
   "source": [
    "# Compare TF Hub model to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_6_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>77.821522</td>\n",
       "      <td>0.792992</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.770353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>75.984252</td>\n",
       "      <td>0.759163</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.758379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>75.721785</td>\n",
       "      <td>0.756841</td>\n",
       "      <td>0.757218</td>\n",
       "      <td>0.755197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>76.640420</td>\n",
       "      <td>0.769917</td>\n",
       "      <td>0.766404</td>\n",
       "      <td>0.762081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>79.790026</td>\n",
       "      <td>0.811230</td>\n",
       "      <td>0.797900</td>\n",
       "      <td>0.791720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>75.459318</td>\n",
       "      <td>0.754729</td>\n",
       "      <td>0.754593</td>\n",
       "      <td>0.751942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>81.364829</td>\n",
       "      <td>0.814855</td>\n",
       "      <td>0.813648</td>\n",
       "      <td>0.811929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy  precision    recall        f1\n",
       "baseline                 77.821522   0.792992  0.778215  0.770353\n",
       "simple_dense             75.984252   0.759163  0.759843  0.758379\n",
       "lstm                     75.721785   0.756841  0.757218  0.755197\n",
       "gru                      76.640420   0.769917  0.766404  0.762081\n",
       "bidirectional            79.790026   0.811230  0.797900  0.791720\n",
       "conv1d                   75.459318   0.754729  0.754593  0.751942\n",
       "tf_hub_sentence_encoder  81.364829   0.814855  0.813648  0.811929"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
    "                                  \"simple_dense\": model_1_results,\n",
    "                                  \"lstm\": model_2_results,\n",
    "                                  \"gru\": model_3_results,\n",
    "                                  \"bidirectional\": model_4_results,\n",
    "                                  \"conv1d\": model_5_results,\n",
    "                                  \"tf_hub_sentence_encoder\": model_6_results\n",
    "                                  })\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the accuracy to same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
